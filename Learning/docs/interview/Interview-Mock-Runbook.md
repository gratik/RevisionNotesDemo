# Interview Mock Runbook

## Metadata
- Owner: Maintainers
- Last updated: February 15, 2026
- Prerequisites: Interview Role Mock Scripts, Interview Scoring Sheets
- Related examples: Learning/Architecture/IntegratedDomainSlicesCaseStudy.cs, Learning/Testing/TestingFrameworksComparison.cs

Use this runbook to execute consistent, high-signal mock interview sessions.

## Session setup (5 minutes)

1. Select target role track.
2. Choose one matching script from `Interview-Role-Mock-Scripts.md`.
3. Open `Interview-Scoring-Sheets.md` for live scoring.
4. Set timer and no-interruption rule.

## Recommended cadence

- 30-minute round (early practice):
  - 5 min warm-up
  - 18 min technical Q&A
  - 7 min feedback
- 45-minute round (intermediate):
  - 8 min architecture/problem framing
  - 25 min deep technical Q&A
  - 12 min scoring + retrospective
- 60-minute round (final prep):
  - 10 min scenario design
  - 35 min deep dive + follow-ups
  - 15 min score review + next-step plan

## During-session rules

- Answer with constraint-first structure.
- Include one explicit tradeoff in each major answer.
- Include one measurable signal (latency, error rate, queue lag, rollback threshold) in each deep-dive answer.
- Keep answers concise before expanding.

## Scoring workflow

1. Score live with the role scorecard.
2. Mark one strongest signal and one highest-priority gap.
3. Set one measurable target for next session.
4. Track score trend across sessions.

## Retrospective template (10 minutes)

- What answer showed strongest technical depth?
- Where did reasoning become vague or generic?
- Which metric was missing and should be added?
- What one behavior to improve next round?

## Weekly mock plan

- Day 1: Backend script + scoring sheet
- Day 3: Senior/Architect script + whiteboard prompt
- Day 5: Platform/DevOps script + reliability/security focus
- Day 7: Last-day revision sheet + cheat card rapid run

## Interview Answer Block

- 30-second answer: A runbook standardizes mock interviews so progress is measurable and repeatable.
- 2-minute deep dive: I use fixed cadence, role scripts, and scoring templates to identify weak signals quickly and turn them into targeted practice goals.
- Common follow-up: How do you prevent mocks from becoming repetitive?
- Strong response: Rotate role scripts, vary constraints, and require new measurable outcomes each session.
- Tradeoff callout: Overly rigid sessions can reduce adaptability if not paired with variation.

## Interview Bad vs Strong Answer

- Bad answer: “I just practiced random interview questions.”
- Strong answer: “I used role-specific scripts, timed cadence, and scoring sheets; each session produced one measurable improvement target.”
- Why strong wins: It shows disciplined preparation and evidence of iterative improvement.

## Interview Timed Drill

- Time box: 12 minutes.
- Prompt: Run a mini-mock with one question and complete a partial scorecard.
- Required outputs:
  - one structured answer
  - one tradeoff statement
  - one measurable next-step target
- Self-check score (0-3 each): structure, technical depth, improvement clarity.
