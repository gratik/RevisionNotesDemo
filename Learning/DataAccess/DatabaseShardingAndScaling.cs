// ==============================================================================
// Database Sharding and Horizontal Scaling
// ==============================================================================
// WHAT IS THIS?
// Database sharding horizontally partitions data by shard key, distributing load across multiple database instances to handle data exceeding single machine capacity and increase throughput.
//
// WHY IT MATTERS
// ‚úÖ CAPACITY: Store exabytes across thousands of machines | ‚úÖ THROUGHPUT: Distribute operations across shards, handle 100K+ ops/sec | ‚úÖ LATENCY: Queries hit single shard, not all data | ‚úÖ INDEPENDENCE: Shard failures affect only that shard | ‚úÖ GROWTH: Add shards as data grows | ‚úÖ COST: Scale cheaply with commodity hardware
//
// WHEN TO USE
// ‚úÖ Data exceeds single machine (>1TB) | ‚úÖ Throughput exceeds single machine (>10K ops/sec) | ‚úÖ Geographic distribution (regional shards) | ‚úÖ User isolation (each tenant on own shard) | ‚úÖ Growing datasets requiring future scaling
//
// WHEN NOT TO USE
// ‚ùå Data fits comfortably on single machine (<100GB) | ‚ùå Simple CRUD app with low traffic | ‚ùå Complex cross-shard joins required | ‚ùå Team unfamiliar with distributed databases | ‚ùå Strong ACID across shards critical
//
// REAL-WORLD EXAMPLE
// Facebook: User data sharded by user ID (0-999999 on shard 0, 1000000-1999999 on shard 1), 2+ billion users across 10000+ shards, each shard replicated for HA. When single shard failure occurs, 0.0001% of users affected. Re-sharding happens transparently by splitting shard ranges.
// ==============================================================================

using System;
using System.Collections.Generic;

namespace RevisionNotesDemo.DataAccess;

public class DatabaseShardingAndScaling
{
    public static void RunAll()
    {
        Console.WriteLine("\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó");
        Console.WriteLine("‚ïë  Database Sharding and Horizontal Scaling");
        Console.WriteLine("‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n");

        Overview();
        ShardingStrategies();
        PracticalImplementation();
        ScalingMath();
        BestPractices();
    }

    private static void Overview()
    {
        Console.WriteLine("üìñ OVERVIEW:\n");
        Console.WriteLine("Sharding horizontally partitions data by shard key\n");
        Console.WriteLine("Without sharding:\n");
        Console.WriteLine("  Database: Users 1-2,000,000,000\n");
        Console.WriteLine("With sharding (10,000 shards):\n");
        Console.WriteLine("  Shard 0: Users 1-200,000");
        Console.WriteLine("  Shard 1: Users 200,001-400,000");
        Console.WriteLine("  Shard N: Users distributed evenly\n");
        Console.WriteLine("Each shard is independent database instance\n");
    }

    private static void ShardingStrategies()
    {
        Console.WriteLine("üéØ SHARDING STRATEGIES:\n");

        Console.WriteLine("1Ô∏è‚É£ RANGE-BASED SHARDING:");
        Console.WriteLine("  Shard by key range (User IDs 1-1M, 1M-2M, etc.)");
        Console.WriteLine("  Pros: Simple, easy re-sharding");
        Console.WriteLine("  Cons: Hot shards if data skewed (all active users on shard 0)\n");

        Console.WriteLine("2Ô∏è‚É£ HASH-BASED SHARDING:");
        Console.WriteLine("  Shard = hash(user_id) % num_shards");
        Console.WriteLine("  Pros: Data distributed evenly, no hot shards");
        Console.WriteLine("  Cons: Re-sharding requires rehashing all data\n");

        Console.WriteLine("3Ô∏è‚É£ DIRECTORY-BASED SHARDING:");
        Console.WriteLine("  Lookup table: User ID ‚Üí Shard mapping");
        Console.WriteLine("  Pros: Most flexible, enables smart sharding");
        Console.WriteLine("  Cons: Lookup overhead, directory must scale\n");

        Console.WriteLine("4Ô∏è‚É£ GEOGRAPHIC SHARDING:");
        Console.WriteLine("  Shard by region (North America on Shard A, Europe on B)");
        Console.WriteLine("  Pros: Low latency, data residency compliance");
        Console.WriteLine("  Cons: Uneven distribution, cross-shard queries slower\n");
    }

    private static void PracticalImplementation()
    {
        Console.WriteLine("‚öôÔ∏è PRACTICAL IMPLEMENTATION:\n");

        Console.WriteLine("Code example (hash-based):");
        Console.WriteLine("  int shard_id = hash(user_id) % 100;  // 100 shards");
        Console.WriteLine("  connection_string = GetShardConnection(shard_id);");
        Console.WriteLine("  user = db.Users.Where(u => u.Id == user_id).First();\n");

        Console.WriteLine("Cross-shard query (broadcast):");
        Console.WriteLine("  Find all users created yesterday:");
        Console.WriteLine("  Query all 100 shards in parallel");
        Console.WriteLine("  Merge results from all shards");
        Console.WriteLine("  Total time: ~100-200ms (shard latency)\n");

        Console.WriteLine("Re-sharding (splitting shard):");
        Console.WriteLine("  Old: Hash mod 10 (shards 0-9)");
        Console.WriteLine("  New: Hash mod 20 (shards 0-19)");
        Console.WriteLine("  Migration: Move affected data to new shards");
        Console.WriteLine("  Double-write during transition");
        Console.WriteLine("  Cutover: Redirect traffic to new shards\n");
    }

    private static void ScalingMath()
    {
        Console.WriteLine("üìä SCALING MATHEMATICS:\n");

        Console.WriteLine("Single database baseline:");
        Console.WriteLine("  Storage: 1,000 TB (1 PB)");
        Console.WriteLine("  Throughput: 10,000 ops/sec");
        Console.WriteLine("  Shards needed: 1\n");

        Console.WriteLine("With 100 shards:");
        Console.WriteLine("  Storage per shard: 1,000 TB / 100 = 10 TB (manageable)");
        Console.WriteLine("  Throughput per shard: 10,000 / 100 = 100 ops/sec");
        Console.WriteLine("  Total throughput: 100 * 100 = 10,000 ops/sec ‚úì\n");

        Console.WriteLine("With 10,000 shards (Facebook scale):");
        Console.WriteLine("  Storage per shard: 1,000 TB / 10,000 = 100 GB (SSD comfortable)");
        Console.WriteLine("  Throughput per shard: 10,000 / 10,000 = 1 op/sec");
        Console.WriteLine("  Total throughput: 1 * 10,000 = 10,000 ops/sec ‚úì\n");
    }

    private static void BestPractices()
    {
        Console.WriteLine("‚úÖ BEST PRACTICES:\n");

        Console.WriteLine("1. CHOOSE SHARD KEY CAREFULLY:");
        Console.WriteLine("  ‚úì High cardinality (user_id good, status bad)");
        Console.WriteLine("  ‚úì Even distribution (immutable hash)");
        Console.WriteLine("  ‚úì Supports access patterns (query by shard key)");
        Console.WriteLine("  ‚ùå Mutable keys (user email can change)\n");

        Console.WriteLine("2. PLAN FOR RESHARDING:");
        Console.WriteLine("  ‚úì Use consistent hashing (adds/removes shards smoothly)");
        Console.WriteLine("  ‚úì Allocate shard ranges generously (future growth)");
        Console.WriteLine("  ‚úì Double-write during transition");
        Console.WriteLine("  ‚ùå Assume shard count fixed forever\n");

        Console.WriteLine("3. HANDLE CROSS-SHARD OPERATIONS:");
        Console.WriteLine("  ‚úì Broadcast to all shards in parallel");
        Console.WriteLine("  ‚úì Set reasonable timeouts (slow shards don't block)");
        Console.WriteLine("  ‚úì Cache results if data not changing");
        Console.WriteLine("  ‚ùå Synchronous sequential queries across shards\n");

        Console.WriteLine("4. REPLICATE EACH SHARD:");
        Console.WriteLine("  ‚úì Master-slave replication (read scaling)");
        Console.WriteLine("  ‚úì Failover to replica if master down");
        Console.WriteLine("  ‚úì Geographically distributed for disaster recovery");
        Console.WriteLine("  ‚ùå Single-shard with no replication\n");
    }
}
